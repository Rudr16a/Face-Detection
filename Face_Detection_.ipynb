{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJnkud05HjzNKoWZKXkdnw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rudr16a/Face-Detection/blob/main/Face_Detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F7LbqipC3fpw"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "\n",
        "# Initialize MediaPipe Face Detection\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.2)\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "current_time = 0\n",
        "past_time = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    img = cv2.flip(img, 1)\n",
        "\n",
        "    # Convert the image to RGB for MediaPipe\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform face detection\n",
        "    results = face_detection.process(img_rgb)\n",
        "\n",
        "    if results.detections:\n",
        "        for detection in results.detections:\n",
        "            bboxC = detection.location_data.relative_bounding_box\n",
        "            ih, iw, _ = img.shape\n",
        "            bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
        "                   int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "\n",
        "            # Draw bounding box and confidence\n",
        "            cv2.rectangle(img, bbox, (0, 255, 0), 2)\n",
        "            cv2.putText(img, f'{int(detection.score[0] * 100)}%', (bbox[0], bbox[1] - 20),\n",
        "                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
        "\n",
        "    current_time = time.time()\n",
        "    frames_per_second = 1 / (current_time - past_time)\n",
        "    past_time = current_time\n",
        "\n",
        "    cv2.putText(img, f'FPS: {str(int(frames_per_second))}', (20, 20), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
        "    # Display the result\n",
        "    cv2.imshow(\"Webcam\", img)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzZgETbq3sst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}